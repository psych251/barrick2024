---
title: "Replication of Individual Differences in Emotion Prediction and Implications for Social Success by Barrick et al. (2024, Emotion)"
author: "Izzy Aslarus (aslarus@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
format:
  html:
    toc: true
    toc_depth: 3
---

## Introduction

I chose to replicate *Individual Differences in Emotion Prediction and Implications for Social Success* by Barrick et al. (2024, Emotion) because I am interested in the relationship between social cognition (what we know about those around us) and interpersonal emotion regulation (how we help those around us to improve their emotional states). In this study, Barrick et al. focus on subjects' ability to accurately predict how other people transition between different emotions over time. Emotion prediction accuracy is an interesting measure of social cognition that has theoretical links to interpersonal emotion regulation. For instance, someone who is better able to predict how another person's emotions change over time might be better able to simulate the emotional consequences of different interpersonal emotion regulation strategies (e.g., distraction, humor, reappraisal, venting), then intervene with the most effective strategy. Barrick et al. found that emotion prediction accuracy is linked to a constellation of other socioemotional outcomes, such as larger social networks and better  emotion perception from facial expressions. This constellation of outcomes is likewise theoretically relevant for interpersonal emotion regulation (e.g., having a larger social network may be related to being more effective at improving others' emotions when desired).

The main task in Barrick et al. (2024) was the Emotion Transitions Task. In this task, subjects rated the likelihood of a generic other person transitioning between every possible pair of emotions from the following list: irritable, anxious, calm, happy, sad, full of thought, sluggish. The study's key measure of interest, **emotion prediction accuracy**, was operationalized as the correlation between subjects' ratings of a generic other person and a set of average transition probabilities obtained from a preexisting experience sampling dataset. Subjects then completed several other tasks and questionnaires to measure potential correlates of emotion prediction accuracy. First, subjects rated the likelihood that they themselves would transition between every pair of emotions, enabling subjects' **emotion typicality** to be operationalized as the correlation between their ratings of their own emotion transitions and the average transition probabilities. To measure **emotion perception**, subjects completed the multiracial version of the Reading the Mind in the Eyes task. Finally, subjects completed a series of questionnaires: the Toronto Alexithymia Scale, which measures **emotion understanding** (i.e., understanding of one's own internal states); the Communication/Mind-Reading and Social Skills subscales of the Autism Quotient, which measure **autistic traits** related to social difficulties; the UCLA loneliness scale, which measures feelings of **loneliness**; the Multidimensional Scale of Perceived Social Support, which measures feelings of **social support**; and social network nominations, which measure **social network size**. Barrick et al. (2024) found that emotion prediction accuracy was significantly associated with lower loneliness, larger social networks, more typical emotion transitions, better emotion perception, better emotion understanding, and fewer communication difficulties. Counter to the authors' predictions, emotion prediction accuracy was associated with *poorer* social skills, and it was not significantly associated with perceived social support.

There are two main challenges for this replication. Firstly, analyses of the original dataset should be reproduced using code and data available on OSF prior to conducting the replication. This is particularly important because a key element of the analysis involves data from an experience sampling study published prior to Barrick et al.'s 2024 paper, which provides the "ground truth" emotion transitions from which accuracy and typicality are calculated. Therefore, computational reproducibility is needed to validate the operationalization of these two key measures. Secondly, it is possible that there are too many tasks and questionnaires for available resources to support while maintaining sufficient power, which would necessitate narrowing the scope of the replication (e.g., focusing only on social outcomes). The scope of the replication has already been narrowed relative to the original paper, which also examined emotion prediction accuracy at the level of a specific community (e.g., a college campus) and a specific other person (e.g., a close friend). This replication focuses on outcomes related to generic emotion prediction accuracy because of the difficulty of collecting data from subjects in the same community, or from dyads, which would be necessary in order to establish a "ground truth" for specific emotion prediction accuracy.

The repository for this replication can be found here: <https://github.com/psych251/barrick2024/>

Furthermore, the original paper can be found here: <https://github.com/psych251/barrick2024/blob/main/original_paper/barrick2024.pdf>

## Methods

### Power Analysis

I conducted power analyses for two key statistical tests: loneliness predicted by emotion prediction accuracy (i.e., does emotion prediction accuracy have downstream social consequences?), and emotion prediction accuracy predicted by emotion understanding (alexithymia; i.e., does poor understanding of one's own emotions have downstream consequences for one's ability to understand others' emotions?).

Based on the results of these power analyses, I determined that I will be under-powered for the loneliness analysis. Therefore, I will only test whether emotion prediction accuracy is predicted by emotion understanding (alexithymia).

#### Loneliness ~ Emotion Prediction Accuracy

Original effect (with standardized coefficients):

β = −.10, SE = 0.04, t(730) = −2.56, p = .01

Sample size for 80% power: 780
Sample size for 90% power: 1044
Sample size for 95% power: 1290

```{r}

library(pwrss)

power_analysis_80 <-
  power.t.regression(
    # Standardized coefficient
    beta = -0.10,
    # Number of predictors
    k.total = 1,
    # R-squared = t-squared / (t-squared + df)
    r.squared = (-2.56)^2/((-2.56)^2 + 730),
    power = .80,
    alpha = 0.05,
    alternative = "two.sided"
  )

power_analysis_90 <-
  power.t.regression(
    # Standardized coefficient
    beta = -0.10,
    # Number of predictors
    k.total = 1,
    # R-squared = t-squared / (t-squared + df)
    r.squared = (-2.56)^2/((-2.56)^2 + 730),
    power = .90,
    alpha = 0.05,
    alternative = "two.sided"
  )

power_analysis_95 <-
  power.t.regression(
    # Standardized coefficient
    beta = -0.10,
    # Number of predictors
    k.total = 1,
    # R-squared = t-squared / (t-squared + df)
    r.squared = (-2.56)^2/((-2.56)^2 + 730),
    power = .95,
    alpha = 0.05,
    alternative = "two.sided"
  )

power_analysis_80$n
power_analysis_90$n
power_analysis_95$n

```

#### Emotion Prediction Accuracy ~ Emotion Understanding

Original effect (with standardized coefficients):

β = −.35, SE = 0.03, t(1010) = -12.44, p < .001

Sample size for 80% power: 58
Sample size for 90% power: 77
Sample size for 95% power: 94

```{r}

understand_power_analysis_80 <-
  power.t.regression(
    # Standardized coefficient
    beta = -0.35,
    # Number of predictors
    k.total = 1,
    # R-squared = t-squared / (t-squared + df)
    r.squared = (-12.44)^2/((-12.44)^2 + 1010),
    power = .80,
    alpha = 0.05,
    alternative = "two.sided"
  )

understand_power_analysis_90 <-
  power.t.regression(
    # Standardized coefficient
    beta = -0.35,
    # Number of predictors
    k.total = 1,
    # R-squared = t-squared / (t-squared + df)
    r.squared = (-12.44)^2/((-12.44)^2 + 1010),
    power = .90,
    alpha = 0.05,
    alternative = "two.sided"
  )

understand_power_analysis_95 <-
  power.t.regression(
    # Standardized coefficient
    beta = -0.35,
    # Number of predictors
    k.total = 1,
    # R-squared = t-squared / (t-squared + df)
    r.squared = (-12.44)^2/((-12.44)^2 + 1010),
    power = .95,
    alpha = 0.05,
    alternative = "two.sided"
  )

understand_power_analysis_80$n
understand_power_analysis_90$n
understand_power_analysis_95$n

```


### Planned Sample

My planned sample size will be 100 participants. Given the discrepancy in the power analysis for Emotion Understanding (N=58 for 80% power and N=94 for 95% power) and for Loneliness (N=780 for 80% power and N=1290 for 95% power), I will be only be conducting the first analysis (Emotion Prediction Accuracy ~ Emotion Understanding) as my main confirmatory hypothesis test.

### Materials

#### Emotion Transitions Task

Re-used materials from original study, including verbatim wording for task instructions and task blocks. Reproduced original analyses of task performance to obtain the final measure of Emotion Prediction Accuracy. Below is the description of this task from the Methods section of the original study:

"In the emotion transitions task (Thornton & Tamir, 2017), participants rated the likelihood that a person (generic other, community member, or specific person) would transition between two hypothetical mental states... On each trial of this task, participants were presented with two mental states connected by an arrow (e.g., happy → angry) and informed that the state to the left of the arrow is the person’s current state, and the mental state on the right side of the arrow is a mental state the person might experience next. Participants then rated the likelihood of that person making that transition on a continuous scale from 0% to 100%. Instructions did not include a specific time interval for the mental state transition (see Supplemental Methods for complete instructions). Participants rated all possible transitions between mental states, including transitions of a state back to itself and transitions in both directions between states... Emotions for Studies 1–4 (irritable, anxious, calm, happy, sad, full of thought, sluggish) were chosen from a previous study (Tamir et al., 2016)... General emotion prediction accuracy was calculated by correlating participant transition ratings with real-world emotion transition likelihoods between the states that were obtained from a previous experience sampling study (Thornton & Tamir, 2017; Trampe et al., 2015; Wilt et al., 2011; see Supplemental Methods for how ground truths were calculated)" (Barrick et al. 2024).

#### Emotion Understanding Scale

Used same scale as the original study. Below is the description of this scale from the Methods section of the original study:

"To measure participants’ understanding of their emotions, we administered the Toronto Alexithymia Scale, a 20-item self-report scale that measures difficulty describing feelings, difficulty identifying feelings, and externally oriented thinking (Bagby et al., 1994). Participants answer each item on a 5-point scale anchored at strongly disagree to strongly agree. Responses were summed to obtain a total score; higher scores indicate more difficulty understanding emotions" (Barrick et al., 2024).

### Procedure	

#### Participants and exclusions

The original study recruited participants from Amazon's Mechanical Turk, whereas I will recruit 100 participants from Prolific. My replication will be conducted using Qualtrics, which is the same platform used in the original study. I will use the same or similar inclusion criteria as the original study. Firstly, I will recruit participants who have a minimum approval rating of 95% on Prolific, matching this inclusion criterion: "Study participation was restricted to workers in the United States with >95% approval ratings." I will also restrict recruitment to participants who report being fluent in English on Prolific, which is conceptually similar to this exclusion criterion: "Participants... were excluded if they... indicated an English comprehension less than 'Good'." Finally, I will not enable participants to skip questions in my Qualtrics survey, which amounts to a stricter version of this exclusion criterion: "Participants... were excluded if they completed less than half of the questions" (Barrick et al. 2024).

#### Tasks and Scales

After providing informed consent, participants will first complete the Emotion Transitions Task. Next, they will complete the Emotion Understanding Scale. Finally, they will provide demographic information and receive a debrief.

### Analysis Plan

#### Data cleaning

For the Emotion Transitions Task, Emotion Prediction Accuracy will be calculated using the same method as the original study:

"General emotion prediction accuracy was calculated by correlating participant transition ratings with real-world emotion transition likelihoods between the states that were obtained from a previous experience sampling study (Thornton & Tamir, 2017; Trampe et al., 2015; Wilt et al., 2011; see Supplemental Methods for how ground truths were calculated)" (Barrick et al. 2024).

The authors provide ground-truth emotion transition probabilities, which they computed using ecological momentary assessment data normalized by the overall frequency of different emotions. Thus, I will be able to compute Emotion Prediction Accuracy by correlating participants' transition likelihood ratings with the same ground truth transitions used by in the original study.

For the Toronto Alexithymia Scale, scores will be obtained by summing item ratings (with reverse-coding where applicable), as described in the scale instructions.

#### Emotion understanding: Key confirmatory test

This is my key confirmatory analysis, given that my power analysis indicates that the replication will be sufficiently powered to detect the original effect.

Analyses in the original study were as follows:

"To test the roles of internal and external information in emotion prediction, we fit separate linear mixed effects models for each source of information (typicality, emotion understanding, emotion perception) using a REML in R, using the lmer() function of the lme4 package. Initial models consisted of participants’ general emotion prediction accuracy scores as the dependent variable, a fixed effect of information source (typicality, emotion understanding, and emotion perception), a random intercept for study to account for study-level variation, and a random slope for each information source. The random slope term was removed to allow the model to converge, so only the random intercept for study was included as a random effect. p-values and standardized coefficients were obtained using the parameters package in R (Lüdecke et al., 2020)" (Barrick et al. 2024).

Because I will not be collecting multiple waves of data, I will not need to run a multilevel model accounting for study-level variation. Instead, I will use the lm() function to conduct a simple linear regression with emotion prediction accuracy as the dependent variable and emotion understanding as the predictor. I will use the same method as the original study to obtain standardized coefficients from this model.

### Differences from Original Study

I do not anticipate major differences from the original study due to the availability of all materials (i.e., task instructions, ground truth data for calculating Emotion Prediction Accuracy), the use of the same platform (Qualtrics) to administer the task, and the use of an online sample (although the original sample was recruited from Mechanical Turk, whereas I will be recruiting participants from Prolific).

Sample size for my replication (N=100) is based on a power analysis, so it will differ from the sample sizes in the original study across multiple waves of data collection. Sample sizes for each wave of data collection in the original study were based on power analyses for other effects that I am not replicating (e.g., a mediation analysis), so the original sample sizes were mostly larger than my planned replication sample size.

Because the original study collected data in multiple waves that each included a different set of measures, my replication study will be shorter in duration, and will involve fewer tasks and scales, since I am only collecting data relevant for my analyses of interest. Also, my analysis plan differs in that I will not need to conduct multilevel models with random intercepts for each study (i.e., each wave of data collection).

### Methods Addendum (Post Data Collection)

You can comment this section out prior to final report with data collection.

#### Actual Sample
  Sample size, demographics, data exclusions based on rules spelled out in analysis plan

#### Differences from pre-data collection methods plan
  Any differences from what was described as the original plan, or “none”.


## Results


### Data preparation

Data preparation following the analysis plan.

#### Libraries and data import

Note: run "anonymize.R" in the data/scripts folder first!
	
```{r include=F}

library(here)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(parameters)
library(lm.beta)
library(ggeffects)

# Raw data from qualtrics (with identifiable columns removed)

raw_pilot_a <-
  here(
    "data", "raw", "anonymous",
    "raw_anon_pilot_a_anon.csv"
  ) %>%
  read_csv() %>%
  filter(sub_id %in% 1:4)

raw_pilot_b <-
  here(
    "data", "raw", "anonymous",
    "raw_anon_pilot_b_anon.csv"
  ) %>%
  read_csv() %>%
  filter(sub_id %in% 7:8)

# Ground truth emotion transitions from original study

gt_emo_transitions <-
  read_csv(here("data", "ground_truth", "gt.csv")) %>%
  rename(
    from = state1, to = state2, ground_truth = Rating
  ) %>%
  mutate(
    from = ifelse(
      from == "full-thought", "full of thought", from
    ),
    to = ifelse(
      to == "full-thought", "full of thought", to
    )
  )

```

#### Compute emotion prediction accuracy

##### Pilot A

```{r include = F}

# Get emotion transition ratings

emo_transitions_pilot_a <- raw_pilot_a %>%
  # Select only emotion transition trials
  select(
    sub_id, 
    contains(
      c("irritable", "anxious", "calm", "happy", "sad", "fot", "sluggish")
    )
  ) %>%
  # Get rid of "_1" at end of variable names
  rename_with(
    ~ sub("_1$", "", .x)
  ) %>%
  # Long format
  pivot_longer(
    cols = !sub_id,
    names_to = c("from", "to"),
    values_to = "probability",
    names_sep = "_"
  ) %>%
  mutate(
    from = ifelse(
      from == "fot", "full of thought", from
    ),
    to = ifelse(
      to == "fot", "full of thought", to
    )
  )

# Compute accuracy

emo_predict_accuracy_pilot_a <- emo_transitions_pilot_a %>%
  left_join(
    gt_emo_transitions,
    by = c("from" = "from", "to" = "to")
  ) %>%
  group_by(sub_id) %>%
  summarize(
    accuracy = cor(probability, ground_truth, use = "pairwise.complete.obs"),
    .groups = "drop"
  )

```

##### Pilot B

```{r include = F}

# Get emotion transition ratings

emo_transitions_pilot_b <- raw_pilot_b %>%
  # Select only emotion transition trials
  select(
    sub_id, 
    contains(
      c("irritable", "anxious", "calm", "happy", "sad", "fot", "sluggish")
    )
  ) %>%
  # Get rid of "_1" at end of variable names
  rename_with(
    ~ sub("_1$", "", .x)
  ) %>%
  # Long format
  pivot_longer(
    cols = !sub_id,
    names_to = c("from", "to"),
    values_to = "probability",
    names_sep = "_"
  ) %>%
  mutate(
    from = ifelse(
      from == "fot", "full of thought", from
    ),
    to = ifelse(
      to == "fot", "full of thought", to
    )
  )

# Compute accuracy

emo_predict_accuracy_pilot_b <- emo_transitions_pilot_b %>%
  left_join(
    gt_emo_transitions,
    by = c("from" = "from", "to" = "to")
  ) %>%
  group_by(sub_id) %>%
  summarize(
    accuracy = cor(probability, ground_truth, use = "pairwise.complete.obs"),
    .groups = "drop"
  )

```

#### Compute emotion understanding

##### Pilot A

```{r include = F}
ques_demo_pilot_a <- raw_pilot_a %>%
  # Select only questionnaires and demographics
  select(
    sub_id, age, gender, race,
    contains(
      c("tas")
    )
  ) %>%
  # Transform questionnaire responses to numeric
  mutate(
    across(
      contains(c("tas")),
      ~ as.numeric(.x)
    )
  ) %>%
  # Change values for reverse-scored TAS alexithymia items
  mutate(
    across(
      c("tas_describefeel_9R", "tas_exorthink_13R", "tas_exorthink_15R",
        "tas_exorthink_18R", "tas_exorthink_19R"),
      ~ 6 - .x
    )
  ) %>%
  # Calculate TAS alexithymia total and subscale scores
  mutate(
    tas_total = rowSums(across(contains("tas"))),
    tas_idfeel = rowSums(across(contains("tas_idfeel"))),
    tas_describefeel = rowSums(across(contains("tas_describefeel"))),
    tas_exorthink = rowSums(across(contains("tas_exorthink")))
  ) %>%
  select(
    sub_id, age, gender, race,
    tas_total, tas_idfeel, tas_describefeel, tas_exorthink
  )
```

##### Pilot B

```{r include = F}
ques_demo_pilot_b <- raw_pilot_b %>%
  # Select only questionnaires and demographics
  select(
    sub_id, age, gender, race,
    contains(
      c("tas")
    )
  ) %>%
  # Transform questionnaire responses to numeric
  mutate(
    across(
      contains(c("tas")),
      ~ as.numeric(.x)
    )
  ) %>%
  # Change values for reverse-scored TAS alexithymia items
  mutate(
    across(
      c("tas_describefeel_9R", "tas_exorthink_13R", "tas_exorthink_15R",
        "tas_exorthink_18R", "tas_exorthink_19R"),
      ~ 6 - .x
    )
  ) %>%
  # Calculate TAS alexithymia total and subscale scores
  mutate(
    tas_total = rowSums(across(contains("tas"))),
    tas_idfeel = rowSums(across(contains("tas_idfeel"))),
    tas_describefeel = rowSums(across(contains("tas_describefeel"))),
    tas_exorthink = rowSums(across(contains("tas_exorthink")))
  ) %>%
  select(
    sub_id, age, gender, race,
    tas_total, tas_idfeel, tas_describefeel, tas_exorthink
  )
```

#### Visualize emotion transitions

##### Ground truth

```{r}

gt_emo_transitions %>%
  mutate(
    from = factor(
      from,
      levels = c("irritable", "anxious", "sad", "sluggish",
                 "full of thought", "calm", "happy")
    ),
    to = factor(
      to,
      levels = c("irritable", "anxious", "sad", "sluggish",
                 "full of thought", "calm", "happy")
    )
  ) %>%
  ggplot(
    aes(x = from, y = to, fill = ground_truth)
  ) +
  geom_raster() +
  scale_fill_distiller(
    name = "\nTransition\nlikelihood",
    palette = "Spectral"
  ) +
  coord_fixed() +
  labs(
    x = "From (State 1)",
    y = "To (State 2)",
    title = "Ground truth emotion transitions"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

# ggsave(here("figures", "pilot", "gt_plot.png"), width = 3.5, height = 3)

```

##### Participants

###### Pilot A

```{r}

emo_transitions_pilot_a %>%
  left_join(
    emo_predict_accuracy_pilot_a,
    by = c("sub_id" = "sub_id")
  ) %>%
  mutate(
    facet_label = str_c("Accuracy = ", round(accuracy, 2))
  ) %>%
  mutate(
    from = factor(
      from,
      levels = c("irritable", "anxious", "sad", "sluggish",
                 "full of thought", "calm", "happy")
    ),
    to = factor(
      to,
      levels = c("irritable", "anxious", "sad", "sluggish",
                 "full of thought", "calm", "happy")
    )
  ) %>%
  ggplot(
    aes(x = from, y = to, fill = probability)
  ) +
  geom_raster() +
  scale_fill_distiller(
    name = "Probability\nrating",
    palette = "Spectral"
  ) +
  coord_fixed() +
  labs(
    x = "From (State 1)",
    y = "To (State 2)",
    title = "Pilot participants' emotion transition predictions"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  ) +
  facet_wrap(vars(facet_label))

# ggsave(here("figures", "pilot", "pilot_a_predictions_plot.png"), width = 6, height = 6)

```

###### Pilot B

```{r}

emo_transitions_pilot_b %>%
  left_join(
    emo_predict_accuracy_pilot_b,
    by = c("sub_id" = "sub_id")
  ) %>%
  mutate(
    facet_label = str_c("Accuracy = ", round(accuracy, 2))
  ) %>%
  mutate(
    from = factor(
      from,
      levels = c("irritable", "anxious", "sad", "sluggish",
                 "full of thought", "calm", "happy")
    ),
    to = factor(
      to,
      levels = c("irritable", "anxious", "sad", "sluggish",
                 "full of thought", "calm", "happy")
    )
  ) %>%
  ggplot(
    aes(x = from, y = to, fill = probability)
  ) +
  geom_raster() +
  scale_fill_distiller(
    name = "Probability\nrating",
    palette = "Spectral"
  ) +
  coord_fixed() +
  labs(
    x = "From (State 1)",
    y = "To (State 2)",
    title = "Pilot participants' emotion transition predictions"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  ) +
  facet_wrap(vars(facet_label))

# ggsave(here("figures", "pilot", "pilot_b_predictions_plot.png"), width = 6, height = 6)

```


### Confirmatory analysis

#### Test

##### Pilot B

```{r}

tas_acc_model_pilot_a <- emo_predict_accuracy_pilot_a %>%
  left_join(ques_demo_pilot_a, by = c("sub_id" = "sub_id")) %>%
  lm(
    accuracy ~ tas_total,
    data = .
  )

# Same method for standardizing coefficients as in original analyses

model_parameters(tas_acc_model_pilot_a, standardize = 'refit')
coef(tas_acc_model_pilot_a)

```

##### Pilot B

```{r}

tas_acc_model_pilot_b <- emo_predict_accuracy_pilot_b %>%
  left_join(ques_demo_pilot_b, by = c("sub_id" = "sub_id")) %>%
  lm(
    accuracy ~ tas_total,
    data = .
  )

# Same method for standardizing coefficients as in original analyses

model_parameters(tas_acc_model_pilot_b, standardize = 'refit')
coef(tas_acc_model_pilot_b)

```

#### Visualize

##### Pilot A

```{r}

tas_acc_model_pilot_a %>%
  predict_response(
    terms = c("tas_total [all]")
  ) %>%
  plot(show_data = TRUE) +
  labs(
    x = "Toronto Alexithymia Score",
    y = "Emotion Prediction Accuracy",
    title = "Emotion Understanding"
  ) +
  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5))

# ggsave(here("figures", "pilot", "tas_acc_plot_pilot_a.png"), width = 4, height = 3)

```

##### Pilot B

```{r}

tas_acc_model_pilot_b %>%
  predict_response(
    terms = c("tas_total [all]")
  ) %>%
  plot(show_data = TRUE) +
  labs(
    x = "Toronto Alexithymia Score",
    y = "Emotion Prediction Accuracy",
    title = "Emotion Understanding"
  ) +
  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5))

# ggsave(here("figures", "pilot", "tas_acc_plot_pilot_b.png"), width = 4, height = 3)

```

*Side-by-side graph with original graph is ideal here*

### Exploratory analyses

## Discussion

### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.  

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.
